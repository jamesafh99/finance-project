{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "676c5a5c",
   "metadata": {},
   "source": [
    "## **3. Risk analysis & stress testing**\n",
    "\n",
    "**OVERVIEW**\n",
    "\n",
    "This section introduces the first components of the portfolio’s risk profile. The objective is to understand how the portfolio behaves under adverse conditions and to quantify the characteristics of its equity curve.\n",
    "\n",
    "Specifically, this step will:\n",
    "- Reconstruct and analyse the portfolio’s equity curve.\n",
    "- Quantify drawdowns, their duration and recovery patterns.\n",
    "- Study rolling volatility over different horizons (30 / 60 / 90 days).\n",
    "- Compute daily risk metrics such as historical and parametric VaR.\n",
    "- Estimate tail risk via CVaR / Expected Shortfall.\n",
    "- Measure the probability of loss over different loss thresholds.\n",
    "- Assess the portfolio’s behaviour relative to a market benchmark (beta and correlation).\n",
    "- Perform hypothetical and historical stress tests on the portfolio.\n",
    "- Summarise the overall risk profile in a concise, decision-oriented set of insights.\n",
    "\n",
    "**SUMMARY RESULTS**\n",
    "\n",
    "- The drawdown analysis shows that the portfolio typically spends around **10 days** under water with an average maximum loss of roughly **–1.5%** per drawdown episode\n",
    "- However, it has also experienced a **very extended drawdown of 310 days** and a **deep peak-to-trough loss of about –24% during early 2020**, which sets the baseline for the more detailed risk and stress-testing work that follows in this phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2da07c2",
   "metadata": {},
   "source": [
    "#### **3.1 Importing necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70d31963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm, t\n",
    "import matplotlib.pyplot as plt\n",
    "from src.helpers_io import read_csv_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c2d74b",
   "metadata": {},
   "source": [
    "#### **3.2 Loading `asset_universe.csv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60723fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading processed data\n",
    "processed_data = read_csv_processed(\"asset_universe.csv\", parse_dates=[\"Date\"]).set_index(\"Date\").sort_index()\n",
    "\n",
    "# Splitting risk-free rate (IRX) from the asset universe\n",
    "annual_risk_free = processed_data[\"IRX\"]\n",
    "asset_universe = processed_data.drop(columns=[\"IRX\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77897b68",
   "metadata": {},
   "source": [
    "#### **3.3 Data cleaning and calculations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26efd48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\james\\Desktop\\UK Life\\Data Scientist Career Path\\My notes (Python, SQL, etc.)\\Portfolio of projects\\finance-project\\env\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:395: RuntimeWarning: invalid value encountered in log\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Computing log and simple returns for further analysis\n",
    "log_returns = pd.DataFrame(np.log(asset_universe / asset_universe.shift(1))).dropna()\n",
    "simple_returns = ((asset_universe / asset_universe.shift(1)) - 1).dropna().reindex(index=log_returns.index).ffill()\n",
    "\n",
    "# Calculating weights\n",
    "weights = pd.Series(1 / len(asset_universe.columns), index= asset_universe.columns, name=\"equal_weights\")\n",
    "\n",
    "# Portfolio returns\n",
    "log_port_returns = (log_returns * weights).sum(axis=1).rename(\"log_port_returns\")\n",
    "simple_port_returns = (simple_returns * weights).sum(axis=1).rename(\"simple_port_returns\")\n",
    "\n",
    "# Cumulative capital over 2019-2024\n",
    "initial_capital = 100_000\n",
    "equity_curve = (initial_capital * (1 + simple_port_returns).cumprod()).rename(\"equity_curve\")\n",
    "\n",
    "# Daily drawdown (%)\n",
    "rolling_peak = equity_curve.cummax()\n",
    "daily_drawdown = ((equity_curve / rolling_peak) - 1).rename(\"daily_drawdown\")\n",
    "\n",
    "# Daily risk-free rate\n",
    "rf_aligned = annual_risk_free.reindex(index=log_port_returns.index).ffill()\n",
    "trading_days = 252  # Typical trading days in a year\n",
    "daily_rf = ((1 + (rf_aligned / 100)) ** (1 / trading_days) - 1).rename(\"daily_rf\")\n",
    "\n",
    "# Concatenating data\n",
    "risk_data = pd.concat([log_port_returns, simple_port_returns, equity_curve, daily_drawdown, daily_rf], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41c0fea",
   "metadata": {},
   "source": [
    "#### **3.4 Drawdown insights**\n",
    "\n",
    "In this subsection, the focus is on how the portfolio behaves once it falls below its previous peak. The starting point is the equity curve, from which daily drawdowns are computed as:\n",
    "\n",
    "$$\n",
    "DD_t = \\frac{E_t}{\\max_{i \\le t} E_i} - 1,\n",
    "$$\n",
    "\n",
    "where $E_t$ is the portfolio equity at time $t$ and $\\max_{i \\leq t} E_i$ is the running peak up to that date.\n",
    "\n",
    "A drawdown episode is defined as any continuous period where $DD_t < 0$. These episodes are then grouped and summarised by:\n",
    "\n",
    "- Start and end dates of each drawdown.\n",
    "- Number of days spent under water (episode duration).\n",
    "- Maximum depth within the episode (worst point of the drawdown).\n",
    "\n",
    "This structure provides a clear view of how often the portfolio enters drawdown, how long it tends to stay there, and how severe those episodes typically are, forming the first building block of the broader risk analysis in this phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68cd0667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drawdown insights\n",
      "\n",
      "Average DD duration: 10 days\n",
      "Average DD: -1.52%\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "longest_drawdown",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "max_drawdown_global",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "4ecc0bc7-336c-432c-8097-9dee83bc129f",
       "rows": [
        [
         "start",
         "2022-03-31 00:00:00",
         "2020-02-20 00:00:00"
        ],
        [
         "end",
         "2023-07-11 00:00:00",
         "2020-05-14 00:00:00"
        ],
        [
         "duration_days",
         "310",
         "56"
        ],
        [
         "max_drawdown",
         "-0.1812904436165459",
         "-0.2382772146063944"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longest_drawdown</th>\n",
       "      <th>max_drawdown_global</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>2022-03-31 00:00:00</td>\n",
       "      <td>2020-02-20 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <td>2023-07-11 00:00:00</td>\n",
       "      <td>2020-05-14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_days</th>\n",
       "      <td>310</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_drawdown</th>\n",
       "      <td>-0.18129</td>\n",
       "      <td>-0.238277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  longest_drawdown  max_drawdown_global\n",
       "start          2022-03-31 00:00:00  2020-02-20 00:00:00\n",
       "end            2023-07-11 00:00:00  2020-05-14 00:00:00\n",
       "duration_days                  310                   56\n",
       "max_drawdown              -0.18129            -0.238277"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating a function for scalability\n",
    "def drawdown_insights(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # Creating boolean mask to detect when a drawdown happens\n",
    "    bool_mask = df[\"daily_drawdown\"] < 0\n",
    "\n",
    "    # Detecting all blocks where there were a drawdown (%)\n",
    "    dd_blocks = (bool_mask != bool_mask.shift()).cumsum().where(bool_mask)\n",
    "\n",
    "    # Adding IDs to each block\n",
    "    temp_df = df[[\"daily_drawdown\"]].copy()\n",
    "    temp_df[\"block_id\"] = dd_blocks\n",
    "    temp_df = temp_df.dropna()\n",
    "\n",
    "    # Grouping data by 'block_id'\n",
    "    dd_summary = (\n",
    "        temp_df\n",
    "        .groupby(\"block_id\")\n",
    "        .agg(\n",
    "            start=(\"daily_drawdown\", lambda x: x.index.min()),\n",
    "            end=(\"daily_drawdown\", lambda x: x.index.max()),\n",
    "            duration_days=(\"daily_drawdown\", \"size\"),\n",
    "            max_drawdown=(\"daily_drawdown\", \"min\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return dd_summary.sort_values(by=\"max_drawdown\", ascending=True)\n",
    "\n",
    "# Drawdown insights\n",
    "drawdown_summary = drawdown_insights(risk_data)\n",
    "\n",
    "longest_dd_block = drawdown_summary[\"duration_days\"].idxmax()   # Longest drawdown (by duration)\n",
    "worst_dd_block = drawdown_summary[\"max_drawdown\"].idxmin()  # Deepest drawdown (by magnitude)\n",
    "average_duration = drawdown_summary[\"duration_days\"].mean()\n",
    "average_drawdown = drawdown_summary[\"max_drawdown\"].mean()\n",
    "\n",
    "# Results\n",
    "results = drawdown_summary.loc[[longest_dd_block, worst_dd_block]].T\n",
    "results.columns = [\"longest_drawdown\", \"max_drawdown_global\"]\n",
    "\n",
    "print(f\"\"\"Drawdown insights\n",
    "\n",
    "Average DD duration: {average_duration:.0f} days\n",
    "Average DD: {average_drawdown:.2%}\"\"\")\n",
    "\n",
    "display(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
